import os
import json
import shutil
import uuid
import cv2
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Header, Depends
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from starlette.responses import Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from datetime import datetime
import time
import hashlib
import secrets

# ============================================================
# ğŸš€ MediaPipe ìµœì í™” + MCP í‘œì¤€ AI ì˜ìƒ ë¶„ì„ ì‹œìŠ¤í…œ
# ============================================================
# ì„±ëŠ¥: MediaPipe Face Detection + í”„ë ˆì„ ìŠ¤í‚µ + í•´ìƒë„ ë‹¤ìš´ì‚¬ì´ì§•
# ë³´ì•ˆ: MCP(Model Context Protocol) í‘œì¤€ ì¸í„°í˜ì´ìŠ¤
# ============================================================

print("=" * 60)
print("ğŸš€ AI Blur System v3.0 - MediaPipe + MCP")
print("=" * 60)

# ============== MediaPipe ì´ˆê¸°í™” (ê°€ë²¼ìš´ ëª¨ë¸) ==============
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

FACE_DETECTOR = None
FACE_CASCADE = None  # Fallback

def init_face_detector():
    global FACE_DETECTOR, FACE_CASCADE
    try:
        model_path = "/opt/ai/backend/blaze_face_short_range.tflite"
        if not os.path.exists(model_path):
            import urllib.request
            url = "https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite"
            print("ğŸ“¥ Downloading MediaPipe model...")
            urllib.request.urlretrieve(url, model_path)
        
        base_options = python.BaseOptions(model_asset_path=model_path)
        options = vision.FaceDetectorOptions(
            base_options=base_options,
            min_detection_confidence=0.5
        )
        FACE_DETECTOR = vision.FaceDetector.create_from_options(options)
        print("âœ… MediaPipe Face Detector loaded")
    except Exception as e:
        print(f"âš ï¸ MediaPipe failed: {e}, using Haar Cascade")
        FACE_CASCADE = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

init_face_detector()

# ============== YOLO ë²ˆí˜¸íŒ ëª¨ë¸ (ByteTrack ì¶”ì ) ==============
LICENSE_PLATE_MODEL = None
BYTETRACK_CONFIG = "/opt/ai/backend/bytetrack.yaml"
try:
    from ultralytics import YOLO
    # ë²ˆí˜¸íŒ ì „ìš© ëª¨ë¸ ì‚¬ìš© (ë” ì •í™•)
    LICENSE_PLATE_MODEL = YOLO("/opt/ai/backend/yolov8n-license-plate.pt")
    LICENSE_PLATE_MODEL.fuse()  # ëª¨ë¸ ìµœì í™”
    print("âœ… YOLO License Plate model loaded & fused")
    print("âœ… ByteTrack tracking enabled")
except Exception as e:
    print(f"âš ï¸ License plate model: {e}")

# ============== MCP (Model Context Protocol) ==============
# API Key ê¸°ë°˜ ì¸ì¦ + ë°ì´í„° ìƒŒë“œë°•ì‹±
MCP_API_KEYS = {
    "mcp_admin_key_2024": {"role": "admin", "permissions": ["read", "write", "analyze"]},
    "mcp_viewer_key_2024": {"role": "viewer", "permissions": ["read"]},
}

# ë¶„ì„ ë¡œê·¸ ì €ì¥ì†Œ (ìƒŒë“œë°•ì‹±ëœ ë¦¬ì†ŒìŠ¤)
MCP_ANALYSIS_LOGS: List[Dict[str, Any]] = []
MCP_ALLOWED_RESOURCES = ["/video/", "/logs/", "/analysis/"]

class MCPAuthError(Exception):
    pass

def verify_mcp_key(api_key: str, required_permission: str = "read") -> Dict:
    """MCP API Key ê²€ì¦ ë° ê¶Œí•œ í™•ì¸"""
    if api_key not in MCP_API_KEYS:
        raise MCPAuthError("Invalid MCP API Key")
    
    key_info = MCP_API_KEYS[api_key]
    if required_permission not in key_info["permissions"]:
        raise MCPAuthError(f"Permission denied: {required_permission}")
    
    return key_info

def log_mcp_access(api_key: str, action: str, resource: str, details: Dict = None):
    """MCP ì ‘ê·¼ ë¡œê·¸ ê¸°ë¡ (ë³´ì•ˆ ê°ì‚¬ìš©)"""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "api_key_hash": hashlib.sha256(api_key.encode()).hexdigest()[:16],
        "action": action,
        "resource": resource,
        "details": details or {}
    }
    MCP_ANALYSIS_LOGS.append(log_entry)
    # ìµœê·¼ 1000ê°œë§Œ ìœ ì§€
    if len(MCP_ANALYSIS_LOGS) > 1000:
        MCP_ANALYSIS_LOGS.pop(0)

# ============== FastAPI ì„¤ì • ==============
app = FastAPI(
    title="AI Blur API + MCP",
    version="3.0.0",
    description="MediaPipe ìµœì í™” + MCP í‘œì¤€ ë³´ì•ˆ í”„ë¡œí† ì½œ"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

UPLOAD_DIR = "/opt/ai/frontend/video"
os.makedirs(UPLOAD_DIR, exist_ok=True)

posts_db = []
post_id_counter = 1
POSTS_DB_FILE = "/opt/ai/backend/posts_data.json"

def load_posts_db():
    """JSON íŒŒì¼ì—ì„œ ê²Œì‹œê¸€ ë¡œë“œ"""
    global posts_db, post_id_counter
    try:
        if os.path.exists(POSTS_DB_FILE):
            with open(POSTS_DB_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                posts_db = data.get("posts", [])
                post_id_counter = data.get("next_id", 1)
                print(f"âœ… Loaded {len(posts_db)} posts from {POSTS_DB_FILE}")
        else:
            posts_db = []
            post_id_counter = 1
            print(f"ğŸ“ No existing posts file, starting fresh")
    except Exception as e:
        print(f"âš ï¸ Error loading posts: {e}")
        posts_db = []
        post_id_counter = 1

def save_posts_db():
    print(f"ğŸ’¾ Saving posts to {POSTS_DB_FILE}...")
    """ê²Œì‹œê¸€ì„ JSON íŒŒì¼ì— ì €ì¥"""
    try:
        with open(POSTS_DB_FILE, 'w', encoding='utf-8') as f:
            json.dump({"posts": posts_db, "next_id": post_id_counter}, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ Error saving posts: {e}")

# ì„œë²„ ì‹œì‘ ì‹œ ë¡œë“œ
load_posts_db()
analysis_tasks = {}
performance_stats = {"total_frames": 0, "total_time": 0, "avg_fps": 0}

class PasswordVerify(BaseModel):
    password: str

# ============== ğŸš€ ìµœì í™”ëœ ë¸”ëŸ¬ ì²˜ë¦¬ í•¨ìˆ˜ ==============

def blur_faces_optimized(frame, scale=0.5):
    """
    MediaPipe ìµœì í™” ì–¼êµ´ ë¸”ëŸ¬
    - í•´ìƒë„ ë‹¤ìš´ì‚¬ì´ì§•ìœ¼ë¡œ ì†ë„ í–¥ìƒ
    - íƒ€ì›í˜• ë¸”ëŸ¬ ì ìš©
    """
    global FACE_DETECTOR, FACE_CASCADE
    
    h, w = frame.shape[:2]
    face_count = 0
    
    # ğŸš€ í•´ìƒë„ ë‹¤ìš´ì‚¬ì´ì§• (ì†ë„ 4ë°° í–¥ìƒ)
    small_h, small_w = int(h * scale), int(w * scale)
    small_frame = cv2.resize(frame, (small_w, small_h))
    
    if FACE_DETECTOR is not None:
        # MediaPipe ì‚¬ìš©
        rgb_small = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_small)
        results = FACE_DETECTOR.detect(mp_image)
        
        for detection in results.detections:
            bbox = detection.bounding_box
            # ì›ë³¸ ì¢Œí‘œë¡œ ë³€í™˜
            x = int(bbox.origin_x / scale)
            y = int(bbox.origin_y / scale)
            bw = int(bbox.width / scale)
            bh = int(bbox.height / scale)
            
            # ê²½ê³„ ì²´í¬
            x, y = max(0, x), max(0, y)
            x2, y2 = min(w, x + bw), min(h, y + bh)
            
            if x2 > x and y2 > y:
                apply_ellipse_blur(frame, x, y, x2, y2)
                face_count += 1
    
    elif FACE_CASCADE is not None:
        # Haar Cascade Fallback
        gray_small = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)
        faces = FACE_CASCADE.detectMultiScale(gray_small, 1.1, 4, minSize=(20, 20))
        
        for (fx, fy, fw, fh) in faces:
            # ì›ë³¸ ì¢Œí‘œë¡œ ë³€í™˜
            x, y = int(fx / scale), int(fy / scale)
            x2, y2 = int((fx + fw) / scale), int((fy + fh) / scale)
            x, y = max(0, x), max(0, y)
            x2, y2 = min(w, x2), min(h, y2)
            
            if x2 > x and y2 > y:
                apply_ellipse_blur(frame, x, y, x2, y2)
                face_count += 1
    
    return frame, face_count

def apply_ellipse_blur(frame, x, y, x2, y2):
    """íƒ€ì›í˜• ë¸”ëŸ¬ ì ìš© (ìµœì í™”)"""
    roi = frame[y:y2, x:x2]
    if roi.size == 0:
        return
    
    # ê°•í™”ëœ ë¸”ëŸ¬: í”½ì…€í™” + ê°€ìš°ì‹œì•ˆ ì´ì¤‘ ì²˜ë¦¬
    h_roi, w_roi = roi.shape[:2]
    if h_roi > 0 and w_roi > 0:
        # 1ì°¨: í”½ì…€í™” (ëª¨ìì´í¬)
        temp = cv2.resize(roi, (max(1, w_roi//12), max(1, h_roi//12)), interpolation=cv2.INTER_LINEAR)
        pixelated = cv2.resize(temp, (w_roi, h_roi), interpolation=cv2.INTER_NEAREST)
        # 2ì°¨: ê°•í•œ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
        blurred = cv2.GaussianBlur(pixelated, (99, 99), 30)
    else:
        blurred = roi
    
    # íƒ€ì› ë§ˆìŠ¤í¬
    h_roi, w_roi = roi.shape[:2]
    mask = np.zeros((h_roi, w_roi), dtype=np.uint8)
    cv2.ellipse(mask, (w_roi//2, h_roi//2), (w_roi//2, h_roi//2), 0, 0, 360, 255, -1)
    
    # ë§ˆìŠ¤í¬ ì ìš©
    mask_3ch = mask[:, :, np.newaxis] / 255.0
    frame[y:y2, x:x2] = (blurred * mask_3ch + roi * (1 - mask_3ch)).astype(np.uint8)

def blur_plates_optimized(frame, cached_boxes=None):
    """
    YOLO ë²ˆí˜¸íŒ ë¸”ëŸ¬ (ìºì‹œ í™œìš© + ByteTrack)
    - í”½ì…€í™” + ê°€ìš°ì‹œì•ˆ ì´ì¤‘ ë¸”ëŸ¬
    - 10% ì˜ì—­ í™•ì¥
    """
    if LICENSE_PLATE_MODEL is None:
        return frame, 0, []
    
    # ìºì‹œëœ ë°•ìŠ¤ ì‚¬ìš© (í”„ë ˆì„ ìŠ¤í‚µ ì‹œ)
    if cached_boxes is not None:
        for (x1, y1, x2, y2) in cached_boxes:
            roi = frame[y1:y2, x1:x2]
            if roi.size > 0:
                h_roi, w_roi = roi.shape[:2]
                if h_roi > 4 and w_roi > 4:
                    temp = cv2.resize(roi, (max(1, w_roi//10), max(1, h_roi//10)), interpolation=cv2.INTER_LINEAR)
                    pixelated = cv2.resize(temp, (w_roi, h_roi), interpolation=cv2.INTER_NEAREST)
                    frame[y1:y2, x1:x2] = cv2.GaussianBlur(pixelated, (99, 99), 30)
        return frame, len(cached_boxes), cached_boxes
    
    # ìƒˆë¡œ ê°ì§€ (ë²ˆí˜¸íŒ í´ë˜ìŠ¤ë§Œ - class 0) + ByteTrack ì¶”ì 
    try:
        results = LICENSE_PLATE_MODEL.track(frame, verbose=False, conf=0.25, imgsz=640, 
                                            classes=[0], persist=True, 
                                            tracker=BYTETRACK_CONFIG)
    except:
        results = LICENSE_PLATE_MODEL(frame, verbose=False, conf=0.25, imgsz=640, classes=[0])
    
    boxes = []
    
    for result in results:
        for box in result.boxes:
            # ë²ˆí˜¸íŒ(class 0)ë§Œ ì²˜ë¦¬
            if int(box.cls[0]) != 0:
                continue
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            
            # ë²ˆí˜¸íŒ ì˜ì—­ 10% í™•ì¥
            pad_x = int((x2 - x1) * 0.1)
            pad_y = int((y2 - y1) * 0.1)
            x1, y1 = max(0, x1 - pad_x), max(0, y1 - pad_y)
            x2, y2 = min(frame.shape[1], x2 + pad_x), min(frame.shape[0], y2 + pad_y)
            
            if x2 > x1 and y2 > y1:
                boxes.append((x1, y1, x2, y2))
                roi = frame[y1:y2, x1:x2]
                if roi.size > 0:
                    h_roi, w_roi = roi.shape[:2]
                    if h_roi > 4 and w_roi > 4:
                        temp = cv2.resize(roi, (max(1, w_roi//10), max(1, h_roi//10)), interpolation=cv2.INTER_LINEAR)
                        pixelated = cv2.resize(temp, (w_roi, h_roi), interpolation=cv2.INTER_NEAREST)
                        frame[y1:y2, x1:x2] = cv2.GaussianBlur(pixelated, (99, 99), 30)
    
    return frame, len(boxes), boxes

# ============== ğŸš€ ìµœì í™”ëœ ì˜ìƒ ì²˜ë¦¬ ==============

def process_video_v3(input_path: str, output_path: str, post_id: int):
    """
    v3.0 ìµœì í™” ì˜ìƒ ì²˜ë¦¬
    - í”„ë ˆì„ ìŠ¤í‚µ: 2ë°° ì†ë„ í–¥ìƒ
    - í•´ìƒë„ ë‹¤ìš´ì‚¬ì´ì§•: 4ë°° ì†ë„ í–¥ìƒ
    - ë²ˆí˜¸íŒ ìºì‹±: ì¶”ê°€ ì†ë„ í–¥ìƒ
    - ëª©í‘œ: 15fps â†’ 30fps+
    """
    global analysis_tasks, performance_stats
    
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        raise Exception(f"Cannot open: {input_path}")
    
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # ì¶œë ¥ ì„¤ì •
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    # ğŸš€ ìµœì í™” íŒŒë¼ë¯¸í„°
    FRAME_SKIP = 2          # ë²ˆí˜¸íŒì€ 2í”„ë ˆì„ë§ˆë‹¤ ê°ì§€
    DETECT_SCALE = 0.5      # ì–¼êµ´ ê°ì§€ëŠ” 50% í•´ìƒë„
    
    frame_count = 0
    total_faces = 0
    total_plates = 0
    cached_plate_boxes = []
    start_time = time.time()
    
    print(f"\n{'='*50}")
    print(f"ğŸ¬ Processing: {os.path.basename(input_path)}")
    print(f"   Input: {width}x{height} @ {fps}fps, {total_frames} frames")
    print(f"   Optimization: SKIP={FRAME_SKIP}, SCALE={DETECT_SCALE}")
    print(f"{'='*50}")
    
    try:
        while True:
            if analysis_tasks.get(post_id) == "STOP":
                print(f"â¹ï¸ Stopped by user")
                return None
            
            ret, frame = cap.read()
            if not ret:
                break
            
            # ğŸš€ ì–¼êµ´ ë¸”ëŸ¬ (ë§¤ í”„ë ˆì„, ë‹¤ìš´ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ë¹ ë¦„)
            frame, faces = blur_faces_optimized(frame, scale=DETECT_SCALE)
            total_faces += faces
            
            # ğŸš€ ë²ˆí˜¸íŒ ë¸”ëŸ¬ (í”„ë ˆì„ ìŠ¤í‚µ + ìºì‹±)
            if frame_count % FRAME_SKIP == 0:
                frame, plates, cached_plate_boxes = blur_plates_optimized(frame)
                total_plates += plates
            else:
                frame, _, _ = blur_plates_optimized(frame, cached_boxes=cached_plate_boxes)
            
            out.write(frame)
            frame_count += 1
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if frame_count % max(1, total_frames // 5) == 0:
                elapsed = time.time() - start_time
                current_fps = frame_count / elapsed if elapsed > 0 else 0
                progress = (frame_count / total_frames) * 100
                print(f"   ğŸ“Š {progress:.0f}% | {current_fps:.1f} fps | Faces: {total_faces}")
        
        # ì™„ë£Œ í†µê³„
        elapsed = time.time() - start_time
        avg_fps = frame_count / elapsed if elapsed > 0 else 0
        
        # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
        performance_stats["total_frames"] += frame_count
        performance_stats["total_time"] += elapsed
        performance_stats["avg_fps"] = performance_stats["total_frames"] / performance_stats["total_time"]
        
        print(f"\n{'='*50}")
        print(f"âœ… COMPLETED!")
        print(f"   Frames: {frame_count} in {elapsed:.1f}s")
        print(f"   Speed: {avg_fps:.1f} fps (Target: 30fps)")
        print(f"   Faces: {total_faces}, Plates: {total_plates}")
        print(f"{'='*50}\n")
        
        return output_path
        
    finally:
        cap.release()
        out.release()

# ============== ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ==============

def run_analysis(post_id: int, input_videos: List[str]):
    global posts_db, analysis_tasks
    
    try:
        analyzed_videos = []
        
        for i, video_url in enumerate(input_videos):
            # URL ê²½ë¡œë¥¼ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€í™˜
            if video_url.startswith("/video/"):
                input_path = os.path.join(UPLOAD_DIR, video_url.replace("/video/", ""))
            else:
                input_path = video_url
            
            print(f"ğŸ“ Input path: {input_path}")
            if not os.path.exists(input_path):
                print(f"âŒ File not found: {input_path}")
                continue
            output_filename = f"analyzed_{post_id}_{i+1}.mp4"
            output_path = os.path.join(UPLOAD_DIR, output_filename)
            
            result = process_video_v3(input_path, output_path, post_id)
            
            if result is None:
                for post in posts_db:
                    if post["id"] == post_id:
                        post["status"] = "PENDING"
                return
            
            analyzed_videos.append(f"/video/{output_filename}")
            
            # MCP ë¡œê·¸ ê¸°ë¡
            log_mcp_access("system", "analyze_complete", f"/video/{output_filename}", {
                "post_id": post_id,
                "input": os.path.basename(input_path)
            })
        
        for post in posts_db:
            if post["id"] == post_id:
                post["status"] = "COMPLETED"
                post["analyzed_video_path"] = json.dumps(analyzed_videos)
        
        print(f"ğŸ‰ Analysis completed for post {post_id}")
        
    except Exception as e:
        print(f"âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        for post in posts_db:
            if post["id"] == post_id:
                post["status"] = "PENDING"
    finally:
        analysis_tasks.pop(post_id, None)

executor = ThreadPoolExecutor(max_workers=2)

# ============== MCP API ì—”ë“œí¬ì¸íŠ¸ ==============

@app.get("/mcp/status")
async def mcp_status():
    """MCP ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "protocol": "MCP",
        "version": "1.0",
        "status": "online",
        "capabilities": ["face_blur", "plate_blur", "video_analysis"],
        "performance": performance_stats
    }

@app.get("/mcp/logs")
async def mcp_get_logs(x_api_key: str = Header(None)):
    """MCP ë¶„ì„ ë¡œê·¸ ì¡°íšŒ (ì¸ì¦ í•„ìš”)"""
    if not x_api_key:
        raise HTTPException(status_code=401, detail="MCP API Key required")
    
    try:
        key_info = verify_mcp_key(x_api_key, "read")
        log_mcp_access(x_api_key, "read_logs", "/mcp/logs")
        return {"logs": MCP_ANALYSIS_LOGS[-100:], "total": len(MCP_ANALYSIS_LOGS)}
    except MCPAuthError as e:
        raise HTTPException(status_code=403, detail=str(e))

@app.get("/mcp/analysis/{post_id}")
async def mcp_get_analysis(post_id: int, x_api_key: str = Header(None)):
    """MCP ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ìƒŒë“œë°•ì‹±)"""
    if not x_api_key:
        raise HTTPException(status_code=401, detail="MCP API Key required")
    
    try:
        key_info = verify_mcp_key(x_api_key, "read")
        
        for post in posts_db:
            if post["id"] == post_id:
                # ìƒŒë“œë°•ì‹±: ë¯¼ê° ì •ë³´ ì œì™¸
                safe_data = {
                    "id": post["id"],
                    "title": post["title"],
                    "status": post["status"],
                    "created_at": post["created_at"],
                    "analyzed_video_path": post.get("analyzed_video_path")
                }
                log_mcp_access(x_api_key, "read_analysis", f"/mcp/analysis/{post_id}")
                return safe_data
        
        raise HTTPException(status_code=404, detail="Not found")
    except MCPAuthError as e:
        raise HTTPException(status_code=403, detail=str(e))

@app.post("/mcp/analyze")
async def mcp_trigger_analysis(post_id: int, x_api_key: str = Header(None)):
    """MCPë¥¼ í†µí•œ ë¶„ì„ íŠ¸ë¦¬ê±° (ê¶Œí•œ í•„ìš”)"""
    if not x_api_key:
        raise HTTPException(status_code=401, detail="MCP API Key required")
    
    try:
        key_info = verify_mcp_key(x_api_key, "analyze")
        log_mcp_access(x_api_key, "trigger_analysis", f"/mcp/analyze/{post_id}")
        
        # ë¶„ì„ íŠ¸ë¦¬ê±° ë¡œì§
        for post in posts_db:
            if post["id"] == post_id and post["status"] == "PENDING":
                return {"status": "ready", "message": "Use /admin/analyze endpoint with video"}
        
        return {"status": "not_available"}
    except MCPAuthError as e:
        raise HTTPException(status_code=403, detail=str(e))

# ============== ê¸°ì¡´ API ==============

@app.post("/api/verify-password")
async def verify_password(data: PasswordVerify):
    return {"status": "success", "valid": data.password == "admin1234"}


@app.post("/request-analysis/")
async def request_analysis(
    title: str = Form(...),
    author: str = Form(...),
    email: str = Form(...),
    password: str = Form(...),
    content: str = Form(default=""),
    target_address: str = Form(default=""),
    phone: str = Form(default=""),
):
    """ë¯¼ì› ì ‘ìˆ˜ (í”„ë¡ íŠ¸ì—”ë“œ í¼ ì „ìš© - ì˜ìƒ ì—†ì´ ì ‘ìˆ˜ë§Œ)"""
    global posts_db, post_id_counter
    
    new_post = {
        "id": post_id_counter, "name": author, "author": author,
        "phone": phone, "email": email, "title": title, "content": content,
        "password": password, "status": "PENDING",
        "created_at": datetime.now().isoformat(),
        "videos": "[]",
        "original_video_filename": "",
        "analyzed_video_path": None, "target_address": target_address
    }
    posts_db.append(new_post)
    post_id = post_id_counter
    post_id_counter += 1
    save_posts_db()
    
    return {"status": "success", "post_id": post_id}

@app.post("/api/posts")
async def create_post(
    title: str = Form(...),
    author: str = Form(...),
    email: str = Form(...),
    password: str = Form(...),
    content: str = Form(default=""),
    target_address: str = Form(default=""),
    phone: str = Form(default=""),
    videos: Optional[List[UploadFile]] = File(default=None)
):
    """ë¯¼ì› ê¸€ ë“±ë¡ + ìë™ AI ë¶„ì„"""
    global posts_db, post_id_counter
    
    saved_videos, original_filenames = [], []
    if videos:
        for video in videos:
            if video.filename:
                ext = os.path.splitext(video.filename)[1] or '.mp4'
                filename = f"original_{post_id_counter}_{uuid.uuid4().hex[:8]}{ext}"
                filepath = os.path.join(UPLOAD_DIR, filename)
                with open(filepath, "wb") as f:
                    shutil.copyfileobj(video.file, f)
                saved_videos.append(f"/video/{filename}")
                original_filenames.append(video.filename)
    
    new_post = {
        "id": post_id_counter, "name": author, "author": author,
        "phone": phone, "email": email, "title": title, "content": content,
        "password": password, "status": "IN_PROGRESS" if saved_videos else "PENDING",
        "created_at": datetime.now().isoformat(),
        "videos": json.dumps(saved_videos) if saved_videos else "[]",
        "original_video_filename": ", ".join(original_filenames),
        "analyzed_video_path": None, "target_address": target_address
    }
    posts_db.append(new_post)
    post_id = post_id_counter
    post_id_counter += 1
    save_posts_db()
    
    # ğŸš€ ì˜ìƒì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ AI ë¶„ì„ ì‹œì‘
    if saved_videos:
        import threading
        def auto_analyze():
            try:
                print(f"ğŸš€ Auto-analysis starting for post {post_id}")
                run_analysis(post_id, saved_videos)
                print(f"âœ… Auto-analysis completed for post {post_id}")
            except Exception as e:
                print(f"âŒ Auto analysis error for post {post_id}: {e}")
                for p in posts_db:
                    if p["id"] == post_id:
                        p["status"] = "ERROR"
                        break
        threading.Thread(target=auto_analyze, daemon=True).start()
    
    return {"status": "success", "post_id": post_id}



@app.get("/api/posts")
async def get_posts(page: int = 1, search: str = "", status_filter: str = ""):
    filtered = [p for p in posts_db if (not search or search.lower() in p.get("title", "").lower())
                and (not status_filter or p["status"] == status_filter)]
    filtered = sorted(filtered, key=lambda x: x["id"], reverse=True)
    per_page, start = 10, (page - 1) * 10
    import json
    data = {
        "posts": [{"id": p["id"], "author": p.get("author", "Unknown"), "name": p.get("name", ""),
                   "title": p["title"], "email": p["email"], "status": p["status"],
                   "created_at": p["created_at"]} for p in filtered[start:start+per_page]],
        "total_posts": len(filtered), "total_pages": (len(filtered) + 9) // 10, "current_page": page
    }
    return Response(content=json.dumps(data, ensure_ascii=False), media_type="application/json; charset=utf-8")

@app.get("/api/posts/{post_id}")
async def get_post(post_id: int):
    for post in posts_db:
        if post["id"] == post_id:
            return post
    raise HTTPException(status_code=404, detail="Not found")

@app.post("/api/posts/{post_id}/verify")
async def verify_post(post_id: int, data: PasswordVerify):
    for post in posts_db:
        if post["id"] == post_id:
            return {"status": "success", "valid": post["password"] == data.password}
    raise HTTPException(status_code=404, detail="Not found")

@app.put("/api/posts/{post_id}")
async def update_post(post_id: int, data: dict):
    for post in posts_db:
        if post["id"] == post_id:
            if post["password"] != data.get("password"):
                raise HTTPException(status_code=403, detail="Password mismatch")
            post.update({k: data.get(k, post.get(k)) for k in ["title", "content", "target_address"]})
            return {"status": "success"}
    raise HTTPException(status_code=404, detail="Not found")

@app.delete("/api/posts/{post_id}")
async def delete_post(post_id: int):
    global posts_db
    for i, post in enumerate(posts_db):
        if post["id"] == post_id:
            posts_db.pop(i)
            save_posts_db()
            return {"status": "success"}
    raise HTTPException(status_code=404, detail="Not found")

@app.post("/admin/analyze/{post_id}")
async def admin_analyze(post_id: int, videos: List[UploadFile] = File(...)):
    global posts_db, analysis_tasks
    for post in posts_db:
        if post["id"] == post_id:
            post["status"] = "IN_PROGRESS"
            input_videos = []
            for i, video in enumerate(videos):
                ext = os.path.splitext(video.filename)[1] or '.mp4'
                filepath = os.path.join(UPLOAD_DIR, f"input_{post_id}_{i+1}{ext}")
                with open(filepath, "wb") as f:
                    shutil.copyfileobj(video.file, f)
                input_videos.append(filepath)
            analysis_tasks[post_id] = "RUNNING"
            executor.submit(run_analysis, post_id, input_videos)
            return {"status": "success", "message": "Analysis started", "post_id": post_id}
    raise HTTPException(status_code=404, detail="Not found")

@app.post("/admin/stop/{post_id}")
async def stop_analysis(post_id: int):
    for post in posts_db:
        if post["id"] == post_id:
            if post["status"] == "IN_PROGRESS":
                analysis_tasks[post_id] = "STOP"
            return {"status": "success"}
    raise HTTPException(status_code=404, detail="Not found")

@app.get("/admin/status/{post_id}")
async def get_analysis_status(post_id: int):
    for post in posts_db:
        if post["id"] == post_id:
            return {"status": post["status"], "analyzed_video_path": post.get("analyzed_video_path")}
    raise HTTPException(status_code=404, detail="Not found")

@app.get("/video/{filename}")
async def serve_video(filename: str):
    filepath = os.path.join(UPLOAD_DIR, filename)
    if os.path.exists(filepath):
        return FileResponse(filepath, media_type="video/mp4")
    raise HTTPException(status_code=404, detail="Not found")

# ì •ì  íŒŒì¼
frontend_dir = "/opt/ai/frontend"
if os.path.exists(frontend_dir):
    app.mount("/static", StaticFiles(directory=os.path.join(frontend_dir, "static")), name="static")

@app.get("/")
async def root():
    index_path = "/opt/ai/frontend/index.html"
    return FileResponse(index_path) if os.path.exists(index_path) else {"message": "Not found"}

@app.get("/{full_path:path}")
async def serve_spa(full_path: str):
    if full_path.startswith(("api", "admin", "static", "video", "mcp")):
        raise HTTPException(status_code=404, detail="Not found")
    index_path = "/opt/ai/frontend/index.html"
    return FileResponse(index_path) if os.path.exists(index_path) else HTTPException(404)

if __name__ == "__main__":
    import uvicorn
    print("\nğŸš€ Starting AI Blur Server with MCP...")
    print("   MCP Endpoint: /mcp/status")
    print("   API Keys: mcp_admin_key_2024, mcp_viewer_key_2024\n")
    uvicorn.run(app, host="0.0.0.0", port=8003)
